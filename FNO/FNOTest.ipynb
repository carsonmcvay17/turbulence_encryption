{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourier Neural Operator Code\n",
    "The goal of this notebook is to implement an FNO for a test dataset. Eventually this code will be used for decoding turbulence simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import jax.numpy as jnp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys in dataset: KeysView(NpzFile '/Users/carsonmcvay/desktop/gradschool/research/turbulence_encryption/forcing_functions/multi_forcing_simulations_combined_viscneg2.npz' with keys: inputs, outputs, metadata)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/carsonmcvay/desktop/gradschool/research/turbulence_encryption/forcing_functions/multi_forcing_simulations_combined_viscneg2.npz\"\n",
    "data = jnp.load(data_path)\n",
    "print(\"keys in dataset:\", data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Inputs Shape: (21, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# Simulated dataset generation\n",
    "# Inputs: Evolved states (e.g., velocity/pressure fields over time)\n",
    "# Targets: Forcing functions (spatially/temporally varying fields)\n",
    "\n",
    "\n",
    "# Example:\n",
    "data_path = \"/Users/carsonmcvay/desktop/gradschool/research/turbulence_encryption/forcing_functions/multi_forcing_simulations_combined_viscneg2.npz\"\n",
    "data = jnp.load(data_path)\n",
    "inputs = data[\"inputs\"]\n",
    "inputs = jnp.fft.irfft(inputs, axis=-1)  # Perform inverse FFT along the last axis # adding this to try to debug\n",
    "outputs = data[\"outputs\"]\n",
    "\n",
    "print(\"Transformed Inputs Shape:\", inputs.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass data to the FNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data from JAX arrays to NumPy\n",
    "# doing this before passing to PyTorch\n",
    "# Convert JAX arrays to NumPy\n",
    "X_train_np = np.array(jnp.asarray(X_train).block_until_ready())  # Ensures conversion to NumPy\n",
    "y_train_np = np.array(jnp.asarray(y_train).block_until_ready())\n",
    "X_test_np = np.array(jnp.asarray(X_test).block_until_ready())\n",
    "y_test_np = np.array(jnp.asarray(y_test).block_until_ready())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging! (Kill me now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_np type: <class 'numpy.ndarray'> shape: (16, 256, 256)\n",
      "y_train_np type: <class 'numpy.ndarray'> shape: (16, 256, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "# Debugging shapes and types\n",
    "print(\"X_train_np type:\", type(X_train_np), \"shape:\", X_train_np.shape)\n",
    "print(\"y_train_np type:\", type(y_train_np), \"shape:\", y_train_np.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay they are still jax arrays, so this is bad. Must convert explicitly to NumPy\n",
    "Yay it is fixed and I do not have to be ritually sacrificed! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNO Architecture\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.fft\n",
    "\n",
    "class FNO2D(nn.Module):\n",
    "    def __init__(self, modes, width, input_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "        modes: number of Fourier modes to retain\n",
    "        width: Feature width for the network\n",
    "        \"\"\"\n",
    "        super(FNO2D, self).__init__()\n",
    "        self.modes = modes\n",
    "        self.width = width\n",
    "\n",
    "        # input and output transforations\n",
    "        self.input_layer = nn.Linear(input_dim, width)\n",
    "        self.output_layer = nn.Linear(width, output_dim)\n",
    "\n",
    "        # Fourier layers\n",
    "        self.fourier_layers = nn.ModuleList([\n",
    "            FourierLayer(modes,width) for i in range(4)\n",
    "        ])\n",
    "\n",
    "        # Non linearity\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten input for the fully connected layer\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, -1)  # Flatten (batch, height*width)\n",
    "\n",
    "        # Input transformation\n",
    "        x = self.input_layer(x)\n",
    "\n",
    "        # pass through Fourier layers\n",
    "        for layer in self.fourier_layers:\n",
    "            x = layer(x)\n",
    "            x = self.activation(x)\n",
    "\n",
    "        # output transformation\n",
    "        x = self.output_layer(x) # (batch, height, width, forcing_channels)\n",
    "        return x.view(batch_size, 256, 256, 2)  # Reshape to match the output (batch, H, W, 2)\n",
    "\n",
    "class FourierLayer(nn.Module):\n",
    "    def __init__(self, modes, width):\n",
    "        super(FourierLayer, self).__init__()\n",
    "        self.modes = modes\n",
    "        self.width = width\n",
    "\n",
    "        # Learnable Foureier filters\n",
    "        self.weights = nn.Parameter(torch.randn(width, modes, modes, dtype=torch.cfloat))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input for FFT\n",
    "        batch_size= x.shape[0]  # Flattened input\n",
    "        height, width = 256, 256  # Replace with your grid dimensions\n",
    "        x = x.view(batch_size, height, width)  # Reshape to 2D grid\n",
    "        \n",
    "        # Fourer transform of input\n",
    "        x_ft = torch.fft.fft2(x, dim=(-2, -1)) # FFT over spatial dimensions\n",
    "\n",
    "        # Retain only the first modes Fourier modes\n",
    "        x_ft = x_ft[...,:self.modes, :self.modes] * self.weights\n",
    "\n",
    "        # Inverse fft\n",
    "        x = torch.fft.ifft2(x_ft, dim=(-2,-1)).real\n",
    "        \n",
    "        \n",
    "\n",
    "    #    Flatten back to a 1D vector\n",
    "        return x.view(batch_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: (21, 256, 256)\n",
      "Outputs shape: (21, 256, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputs shape:\", inputs.shape)  # Should be (num_samples, 256, 256)\n",
    "print(\"Outputs shape:\", outputs.shape)  # Should be (num_samples, 256, 256, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[16, 64]' is invalid for input of size 16384",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m predicted_forcing \u001b[38;5;241m=\u001b[39m fno_model(evolved_state)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(predicted_forcing, forcing_function)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[68], line 39\u001b[0m, in \u001b[0;36mFNO2D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# pass through Fourier layers\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfourier_layers:\n\u001b[0;32m---> 39\u001b[0m     x \u001b[38;5;241m=\u001b[39m layer(x)\n\u001b[1;32m     40\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# output transformation\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[68], line 71\u001b[0m, in \u001b[0;36mFourierLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m  x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mifft2(x_ft, dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mreal\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Flatten back to a 1D vector\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m  \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[16, 64]' is invalid for input of size 16384"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "height, width = 256, 256  # Replace with your grid dimensions\n",
    "input_dim = height * width  # Flattened input size\n",
    "output_dim = height * width * 2  # Flattened output size with 2 channels (forcing_x and forcing_y)\n",
    "\n",
    "# initialize model, optimizer, and loss function\n",
    "fno_model = FNO2D(modes=16, width=64, input_dim=input_dim, output_dim=output_dim)\n",
    "optimizer = torch.optim.Adam(fno_model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for evolved_state, forcing_function in train_loader: #assuming a data loader\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        predicted_forcing = fno_model(evolved_state)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(predicted_forcing, forcing_function)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hate all shapes and matrix multiplicaiton. I must fix this error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "# test on unseen data\n",
    "with torch.no_grad():\n",
    "    for evolved_state, true_forcing in test_loader:\n",
    "        predicted_forcing = fno_model(evolved_state)\n",
    "\n",
    "        # compute error or visualize\n",
    "        error = loss_fn(predicted_forcing, true_forcing)\n",
    "        print(f\"Test Error: {error.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
