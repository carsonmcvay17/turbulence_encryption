{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourier Neural Operator Code\n",
    "The goal of this notebook is to implement an FNO for a test dataset. Eventually this code will be used for decoding turbulence simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/09694/carsonmcvay/ls6/miniconda3/envs/jaxenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import jax.numpy as jnp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys in dataset: KeysView(NpzFile '/home1/09694/carsonmcvay/work/turbulence_encryption/forcing_functions/multi_forcing_simulations_combined_viscneg2.npz' with keys: inputs, outputs, metadata)\n"
     ]
    }
   ],
   "source": [
    "# data_path = \"/Users/carsonmcvay/desktop/gradschool/research/turbulence_encryption/forcing_functions/multi_forcing_simulations_combined_viscneg2.npz\"\n",
    "data_path = \"/home1/09694/carsonmcvay/work/turbulence_encryption/forcing_functions/multi_forcing_simulations_combined_viscneg2.npz\"\n",
    "data = jnp.load(data_path)\n",
    "print(\"keys in dataset:\", data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I guess I should try to run on a GPU since everything keeps breaking when I try to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU :(\n"
     ]
    }
   ],
   "source": [
    "if torch.mps.is_available():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"No GPU :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Simulated dataset generation\n",
    "# Inputs: Evolved states (e.g., velocity/pressure fields over time)\n",
    "# Targets: Forcing functions (spatially/temporally varying fields)\n",
    "\n",
    "\n",
    "# Example:\n",
    "# data_path = \"/Users/carsonmcvay/desktop/gradschool/research/turbulence_encryption/forcing_functions/multi_forcing_simulations_combined_viscneg2.npz\"\n",
    "# data = jnp.load(data_path)\n",
    "inputs = data[\"inputs\"]\n",
    "inputs = jnp.fft.irfft(inputs, axis=-1)  # Perform inverse FFT along the last axis # adding this to try to debug\n",
    "outputs = data[\"outputs\"]\n",
    "\n",
    "print(\"Transformed Inputs Shape:\", inputs.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass data to the FNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data from JAX arrays to NumPy\n",
    "# doing this before passing to PyTorch\n",
    "# Convert JAX arrays to NumPy\n",
    "X_train_np = np.array(jnp.asarray(X_train).block_until_ready())  # Ensures conversion to NumPy\n",
    "y_train_np = np.array(jnp.asarray(y_train).block_until_ready())\n",
    "X_test_np = np.array(jnp.asarray(X_test).block_until_ready())\n",
    "y_test_np = np.array(jnp.asarray(y_test).block_until_ready())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging! (Kill me now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_np type: <class 'numpy.ndarray'> shape: (16, 256, 256)\n",
      "y_train_np type: <class 'numpy.ndarray'> shape: (16, 256, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "# Debugging shapes and types\n",
    "print(\"X_train_np type:\", type(X_train_np), \"shape:\", X_train_np.shape)\n",
    "print(\"y_train_np type:\", type(y_train_np), \"shape:\", y_train_np.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay they are still jax arrays, so this is bad. Must convert explicitly to NumPy. :(\n",
    "Yay it is fixed and I do not have to be ritually sacrificed! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNO Architecture\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.fft\n",
    "\n",
    "class FNO2D(nn.Module):\n",
    "    def __init__(self, modes, width, input_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "        modes: number of Fourier modes to retain\n",
    "        width: Feature width for the network\n",
    "        \"\"\"\n",
    "        super(FNO2D, self).__init__()\n",
    "        self.modes = modes\n",
    "        self.width = width\n",
    "        self.height, self.width_grid = 256, 256  # Assuming a fixed grid size\n",
    "\n",
    "        # # input and output transforations\n",
    "        # self.input_layer = nn.Linear(input_dim, width)\n",
    "        # self.output_layer = nn.Linear(width, output_dim)\n",
    "\n",
    "        # Input and output transformations\n",
    "        # chatgpt claims this will fix it\n",
    "        self.input_layer = nn.Linear(input_dim, self.height * self.width_grid)\n",
    "        self.output_layer = nn.Linear(self.height * self.width_grid, output_dim)\n",
    "\n",
    "        # Fourier layers\n",
    "        self.fourier_layers = nn.ModuleList([\n",
    "            FourierLayer(modes,width) for i in range(4)\n",
    "        ])\n",
    "\n",
    "        # Non linearity\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten input for the fully connected layer\n",
    "        batch_size = x.shape[0]\n",
    "        # print(f\"Input shape to FNO2D: {x.shape}\")\n",
    "        x = x.view(batch_size, -1)  # Flatten (batch, height*width)\n",
    "        # print(f\"Shape after flattening: {x.shape}\")\n",
    "\n",
    "        # Input transformation\n",
    "        x = self.input_layer(x)\n",
    "        # print(f\"Shape after input_layer: {x.shape}\")\n",
    "        # a \"fix\"\n",
    "        x = x.view(batch_size, self.height, self.width_grid)  # Reshape to 2D grid\n",
    "        # print(f\"Shape after reshaping to 2D grid: {x.shape}\")\n",
    "\n",
    "        # pass through Fourier layers\n",
    "        for layer in self.fourier_layers:\n",
    "            x = layer(x)\n",
    "            # print(f\"Shape after Fourier layer: {x.shape}\")\n",
    "            x = self.activation(x)\n",
    "\n",
    "        \n",
    "        # Flatten back to 1D before the output layer\n",
    "        x = x.view(batch_size, -1)  # (batch, height * width)\n",
    "        # print(f\"Shape before output_layer: {x.shape}\")\n",
    "        # output transformation\n",
    "        x = self.output_layer(x) # (batch, height, width, forcing_channels)\n",
    "        # print(f\"Shape after output_layer: {x.shape}\")\n",
    "        return x.view(batch_size, 256, 256, 2)  # Reshape to match the output (batch, H, W, 2)\n",
    "\n",
    "class FourierLayer(nn.Module):\n",
    "    def __init__(self, modes, width):\n",
    "        super(FourierLayer, self).__init__()\n",
    "        self.modes = modes\n",
    "        self.width = width\n",
    "\n",
    "        # Learnable Foureier filters\n",
    "        self.weights = nn.Parameter(torch.randn(width, modes, modes, dtype=torch.cfloat))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input for FFT\n",
    "        batch_size, seq_len = x.shape  # Flattened input\n",
    "        height, width = 256, 256  # Replace with your grid dimensions\n",
    "        assert seq_len == height * width, f\"Input size mismatch: got {seq_len}, expected {height * width}\"\n",
    "        \n",
    "        x = x.view(batch_size, height, width)  # Reshape to 2D grid\n",
    "        \n",
    "        # Fourer transform of input\n",
    "        x_ft = torch.fft.fft2(x, dim=(-2, -1)) # FFT over spatial dimensions\n",
    "\n",
    "        # Retain only the first modes Fourier modes\n",
    "        x_ft = x_ft[...,:self.modes, :self.modes] * self.weights\n",
    "\n",
    "        # Inverse fft\n",
    "        x = torch.fft.ifft2(x_ft, dim=(-2,-1)).real\n",
    "        \n",
    "        \n",
    "\n",
    "    #    Flatten back to a 1D vector\n",
    "        return x.view(batch_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: (21, 256, 256)\n",
      "Outputs shape: (21, 256, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputs shape:\", inputs.shape)  # Should be (num_samples, 256, 256)\n",
    "print(\"Outputs shape:\", outputs.shape)  # Should be (num_samples, 256, 256, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: FNO2D(\n",
      "  (input_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (output_layer): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "  (fourier_layers): ModuleList(\n",
      "    (0-3): 4 x FourierLayer()\n",
      "  )\n",
      "  (activation): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x65536 and 1024x1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward pass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m predicted_forcing \u001b[38;5;241m=\u001b[39m fno_model(evolved_state)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomputing loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1749\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1760\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1758\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1759\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1762\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1763\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[9], line 43\u001b[0m, in \u001b[0;36mFNO2D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten (batch, height*width)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# print(f\"Shape after flattening: {x.shape}\")\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Input transformation\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layer(x)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# print(f\"Shape after input_layer: {x.shape}\")\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# a \"fix\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth_grid)  \u001b[38;5;66;03m# Reshape to 2D grid\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1749\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1760\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1758\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1759\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1762\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1763\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxenv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x65536 and 1024x1024)"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "height, width = 256, 256  # Replace with your grid dimensions\n",
    "input_dim = height * width  # Flattened input size\n",
    "output_dim = height * width * 2  # Flattened output size with 2 channels (forcing_x and forcing_y)\n",
    "\n",
    "# initialize model, optimizer, and loss function\n",
    "fno_model = FNO2D(modes=16, width=64, input_dim=input_dim, output_dim=output_dim)\n",
    "print(f\"model: {fno_model}\")\n",
    "optimizer = torch.optim.Adam(fno_model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# training loop\n",
    "num_epochs = 100\n",
    "for epoch in tqdm(range(num_epochs), desc=\"training\"):\n",
    "    for evolved_state, forcing_function in train_loader: #assuming a data loader\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        print(\"forward pass\")\n",
    "        # forward pass\n",
    "        predicted_forcing = fno_model(evolved_state)\n",
    "\n",
    "        print(\"computing loss\")\n",
    "        # Compute loss\n",
    "        loss = loss_fn(predicted_forcing, forcing_function)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hate all shapes and matrix multiplicaiton. I must fix this error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "# test on unseen data\n",
    "with torch.no_grad():\n",
    "    for evolved_state, true_forcing in test_loader:\n",
    "        predicted_forcing = fno_model(evolved_state)\n",
    "\n",
    "        # compute error or visualize\n",
    "        error = loss_fn(predicted_forcing, true_forcing)\n",
    "        print(f\"Test Error: {error.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
