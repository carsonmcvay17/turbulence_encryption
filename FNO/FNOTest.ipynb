{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourier Neural Operator Code\n",
    "The goal of this notebook is to implement an FNO for a test dataset. Eventually this code will be used for decoding turbulence simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import jax.numpy as jnp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys in dataset: KeysView(NpzFile '/Users/carsonmcvay/desktop/gradschool/research/turbulence_encryption/forcing_functions/multi_forcing_simulations_combined_viscneg2.npz' with keys: inputs, outputs, metadata)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/carsonmcvay/desktop/gradschool/research/turbulence_encryption/forcing_functions/multi_forcing_simulations_combined_viscneg2.npz\"\n",
    "data = jnp.load(data_path)\n",
    "print(\"keys in dataset:\", data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Inputs Shape: (21, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# Simulated dataset generation\n",
    "# Inputs: Evolved states (e.g., velocity/pressure fields over time)\n",
    "# Targets: Forcing functions (spatially/temporally varying fields)\n",
    "\n",
    "\n",
    "# Example:\n",
    "data_path = \"/Users/carsonmcvay/desktop/gradschool/research/turbulence_encryption/forcing_functions/multi_forcing_simulations_combined_viscneg2.npz\"\n",
    "data = jnp.load(data_path)\n",
    "inputs = data[\"inputs\"]\n",
    "inputs = jnp.fft.irfft(inputs, axis=-1)  # Perform inverse FFT along the last axis # adding this to try to debug\n",
    "outputs = data[\"outputs\"]\n",
    "\n",
    "print(\"Transformed Inputs Shape:\", inputs.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass data to the FNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data from JAX arrays to NumPy\n",
    "# doing this before passing to PyTorch\n",
    "# Convert JAX arrays to NumPy\n",
    "X_train_np = np.array(jnp.asarray(X_train).block_until_ready())  # Ensures conversion to NumPy\n",
    "y_train_np = np.array(jnp.asarray(y_train).block_until_ready())\n",
    "X_test_np = np.array(jnp.asarray(X_test).block_until_ready())\n",
    "y_test_np = np.array(jnp.asarray(y_test).block_until_ready())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging! (Kill me now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_np type: <class 'numpy.ndarray'> shape: (16, 256, 256)\n",
      "y_train_np type: <class 'numpy.ndarray'> shape: (16, 256, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "# Debugging shapes and types\n",
    "print(\"X_train_np type:\", type(X_train_np), \"shape:\", X_train_np.shape)\n",
    "print(\"y_train_np type:\", type(y_train_np), \"shape:\", y_train_np.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay they are still jax arrays, so this is bad. Must convert explicitly to NumPy. :(\n",
    "Yay it is fixed and I do not have to be ritually sacrificed! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNO Architecture\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.fft\n",
    "\n",
    "class FNO2D(nn.Module):\n",
    "    def __init__(self, modes, width, input_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "        modes: number of Fourier modes to retain\n",
    "        width: Feature width for the network\n",
    "        \"\"\"\n",
    "        super(FNO2D, self).__init__()\n",
    "        self.modes = modes\n",
    "        self.width = width\n",
    "        self.height, self.width_grid = 256, 256  # Assuming a fixed grid size\n",
    "\n",
    "        # # input and output transforations\n",
    "        # self.input_layer = nn.Linear(input_dim, width)\n",
    "        # self.output_layer = nn.Linear(width, output_dim)\n",
    "\n",
    "        # Input and output transformations\n",
    "        # chatgpt claims this will fix it\n",
    "        self.input_layer = nn.Linear(input_dim, self.height * self.width_grid)\n",
    "        self.output_layer = nn.Linear(self.height * self.width_grid, output_dim)\n",
    "\n",
    "        # Fourier layers\n",
    "        self.fourier_layers = nn.ModuleList([\n",
    "            FourierLayer(modes,width) for i in range(4)\n",
    "        ])\n",
    "\n",
    "        # Non linearity\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten input for the fully connected layer\n",
    "        batch_size = x.shape[0]\n",
    "        # print(f\"Input shape to FNO2D: {x.shape}\")\n",
    "        x = x.view(batch_size, -1)  # Flatten (batch, height*width)\n",
    "        # print(f\"Shape after flattening: {x.shape}\")\n",
    "\n",
    "        # Input transformation\n",
    "        x = self.input_layer(x)\n",
    "        # print(f\"Shape after input_layer: {x.shape}\")\n",
    "        # a \"fix\"\n",
    "        x = x.view(batch_size, self.height, self.width_grid)  # Reshape to 2D grid\n",
    "        # print(f\"Shape after reshaping to 2D grid: {x.shape}\")\n",
    "\n",
    "        # pass through Fourier layers\n",
    "        for layer in self.fourier_layers:\n",
    "            x = layer(x)\n",
    "            # print(f\"Shape after Fourier layer: {x.shape}\")\n",
    "            x = self.activation(x)\n",
    "\n",
    "        \n",
    "        # Flatten back to 1D before the output layer\n",
    "        x = x.view(batch_size, -1)  # (batch, height * width)\n",
    "        # print(f\"Shape before output_layer: {x.shape}\")\n",
    "        # output transformation\n",
    "        x = self.output_layer(x) # (batch, height, width, forcing_channels)\n",
    "        # print(f\"Shape after output_layer: {x.shape}\")\n",
    "        return x.view(batch_size, 256, 256, 2)  # Reshape to match the output (batch, H, W, 2)\n",
    "\n",
    "class FourierLayer(nn.Module):\n",
    "    def __init__(self, modes, width):\n",
    "        super(FourierLayer, self).__init__()\n",
    "        self.modes = modes\n",
    "        self.width = width\n",
    "\n",
    "        # Learnable Foureier filters\n",
    "        self.weights = nn.Parameter(torch.randn(width, modes, modes, dtype=torch.cfloat))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input for FFT\n",
    "        batch_size, seq_len = x.shape  # Flattened input\n",
    "        height, width = 256, 256  # Replace with your grid dimensions\n",
    "        assert seq_len == height * width, f\"Input size mismatch: got {seq_len}, expected {height * width}\"\n",
    "        \n",
    "        x = x.view(batch_size, height, width)  # Reshape to 2D grid\n",
    "        \n",
    "        # Fourer transform of input\n",
    "        x_ft = torch.fft.fft2(x, dim=(-2, -1)) # FFT over spatial dimensions\n",
    "\n",
    "        # Retain only the first modes Fourier modes\n",
    "        x_ft = x_ft[...,:self.modes, :self.modes] * self.weights\n",
    "\n",
    "        # Inverse fft\n",
    "        x = torch.fft.ifft2(x_ft, dim=(-2,-1)).real\n",
    "        \n",
    "        \n",
    "\n",
    "    #    Flatten back to a 1D vector\n",
    "        return x.view(batch_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: (21, 256, 256)\n",
      "Outputs shape: (21, 256, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputs shape:\", inputs.shape)  # Should be (num_samples, 256, 256)\n",
    "print(\"Outputs shape:\", outputs.shape)  # Should be (num_samples, 256, 256, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "height, width = 256, 256  # Replace with your grid dimensions\n",
    "input_dim = height * width  # Flattened input size\n",
    "output_dim = height * width * 2  # Flattened output size with 2 channels (forcing_x and forcing_y)\n",
    "\n",
    "# initialize model, optimizer, and loss function\n",
    "fno_model = FNO2D(modes=16, width=64, input_dim=input_dim, output_dim=output_dim)\n",
    "optimizer = torch.optim.Adam(fno_model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for evolved_state, forcing_function in train_loader: #assuming a data loader\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        predicted_forcing = fno_model(evolved_state)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(predicted_forcing, forcing_function)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hate all shapes and matrix multiplicaiton. I must fix this error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "# test on unseen data\n",
    "with torch.no_grad():\n",
    "    for evolved_state, true_forcing in test_loader:\n",
    "        predicted_forcing = fno_model(evolved_state)\n",
    "\n",
    "        # compute error or visualize\n",
    "        error = loss_fn(predicted_forcing, true_forcing)\n",
    "        print(f\"Test Error: {error.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
