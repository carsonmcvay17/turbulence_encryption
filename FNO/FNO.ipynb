{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook designed to create an FNO which matches evolved turbulence simulations to their forcing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from neuralop.models import FNO\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from neuralop import Trainer\n",
    "from neuralop.training import AdamW\n",
    "from neuralop.utils import count_model_params\n",
    "from sklearn.model_selection import train_test_split\n",
    "from neuralop import LpLoss, H1Loss\n",
    "from named_dataset import NamedTensorDataset\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_path = \"/work/09694/carsonmcvay/ls6/turbulence_encryption/forcing_functions/multi_forcing_simulations_combined_viscneg2.npz\"\n",
    "data = jnp.load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# designate inputs and outputs\n",
    "# inputs are simulations, outputs are forcings\n",
    "inputs = data[\"inputs\"]\n",
    "inputs = jnp.fft.irfft(inputs, axis=-1)  # Perform inverse FFT along the last axis # adding this to try to debug\n",
    "outputs = data[\"outputs\"]\n",
    "\n",
    "print(\"Transformed Inputs Shape:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data from JAX arrays to NumPy\n",
    "# doing this before passing to PyTorch\n",
    "X_train_np = np.array(jnp.asarray(X_train).block_until_ready())  # Ensures conversion to NumPy\n",
    "y_train_np = np.array(jnp.asarray(y_train).block_until_ready())\n",
    "X_test_np = np.array(jnp.asarray(X_test).block_until_ready())\n",
    "y_test_np = np.array(jnp.asarray(y_test).block_until_ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loaders\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32)\n",
    "\n",
    "# Create data loaders\n",
    "# train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "# test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_dataset = NamedTensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = NamedTensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# data_processor = data_processor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat FNO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNO(n_modes=(16,16),\n",
    "           in_channels=1,\n",
    "           out_channels=1, \n",
    "           hidden_channels=32,\n",
    "           projection_channel_ratio=2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "n_params = count_model_params(model)\n",
    "print(f\"our model has {n_params} parameters\")\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                 lr=1e-4,\n",
    "                 weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
    "\n",
    "# create losses\n",
    "l2loss = LpLoss(d=2, p=2)\n",
    "h1loss = H1Loss(d=2)\n",
    "\n",
    "train_loss = h1loss\n",
    "eval_losses={'h1': h1loss, 'l2': l2loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                 lr=1e-4,\n",
    "                 weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
    "\n",
    "# create losses\n",
    "l2loss = LpLoss(d=2, p=2)\n",
    "h1loss = H1Loss(d=2)\n",
    "\n",
    "train_loss = h1loss\n",
    "eval_losses={'h1': h1loss, 'l2': l2loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the trainer\n",
    "trainer = Trainer(model=model, n_epochs=20, \n",
    "                 wandb_log=False,\n",
    "                 device=device,\n",
    "                 mixed_precision=False,\n",
    "                 data_processor=None,\n",
    "                 eval_interval=3,\n",
    "                 log_output=False,\n",
    "                 use_distributed=False,\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model on data\n",
    "trainer.train(train_loader=train_loader, \n",
    "             test_loaders={\"default\": test_loader},\n",
    "             optimizer=optimizer,\n",
    "             scheduler=scheduler,\n",
    "             regularizer=False,\n",
    "             training_loss=train_loss,\n",
    "             eval_losses=eval_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
